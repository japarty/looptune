{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e03f32711a005f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96971ed2-e497-43c4-9a22-47ff7d93c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install proper version of torch, as according to: https://pytorch.org/\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -e ../.\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from looptune import prep_config_combinations, single_run, clean_memory\n",
    "from transformers import Phi3ForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269d739-e320-4d04-aae1-466d6e1f3cbb",
   "metadata": {},
   "source": [
    "### Prepare dataset with two columns: 'text' and 'label'\n",
    "\n",
    "Examplary data source: https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-for-financial-news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca218249-1791-49ec-a1be-fe8927c744e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('example_data/SentimentAnalysisforFinancialNews.csv', encoding=\"ISO-8859-1\", header=None)\n",
    "df.columns = ['label', 'text']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e488de-cfd6-42d1-9280-5823b4394805",
   "metadata": {},
   "source": [
    "### Prepare run configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca629d5cfeeb48dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'microsoft/Phi-3-mini-4k-instruct',\n",
       "  'custom_loader': transformers.models.phi3.modeling_phi3.Phi3ForSequenceClassification,\n",
       "  'split': (0.8, 0.2),\n",
       "  'balanced': (('train',), ('test',)),\n",
       "  'training_arguments': {'num_train_epochs': 3,\n",
       "   'per_device_train_batch_size': 16,\n",
       "   'per_device_eval_batch_size': 16,\n",
       "   'gradient_checkpointing': True,\n",
       "   'save_total_limit': 2,\n",
       "   'load_best_model_at_end': True,\n",
       "   'save_strategy': 'steps',\n",
       "   'metric_for_best_model': 'f1-score',\n",
       "   'evaluation_strategy': 'steps',\n",
       "   'logging_steps': 100,\n",
       "   'fp16': False,\n",
       "   'learning_rate': 5e-05,\n",
       "   'lr_scheduler_type': 'linear',\n",
       "   'warmup_ratio': 0.1,\n",
       "   'max_grad_norm': 0.3,\n",
       "   'weight_decay': 0.001},\n",
       "  'bnb_config': {'bnb_4bit_compute_dtype': torch.bfloat16,\n",
       "   'load_in_4bit': True,\n",
       "   'bnb_4bit_quant_type': 'nf4',\n",
       "   'bnb_4bit_use_double_quant': True,\n",
       "   'load_in_8bit': False},\n",
       "  'peft_config': {'r': 8,\n",
       "   'lora_alpha': 32,\n",
       "   'lora_dropout': 0.01,\n",
       "   'bias': 'none',\n",
       "   'task_type': 'SEQ_CLS',\n",
       "   'target_modules': 'all-linear'}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_config = {   # -----------------------\n",
    "                  'model_name': [\n",
    "                           # 'distilbert/distilbert-base-uncased-finetuned-sst-2-english',\n",
    "                           #  'michellejieli/emotion_text_classifier',\n",
    "                           #  'cardiffnlp/twitter-xlm-roberta-base-sentiment',\n",
    "                           #  'celine98/canine-s-finetuned-sst2',\n",
    "                           #  'lxyuan/distilbert-base-multilingual-cased-sentiments-student',\n",
    "                           #  'michelecafagna26/t5-base-finetuned-sst2-sentiment',\n",
    "                           # 'nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "                           # 'ProsusAI/finbert',\n",
    "                           # 'arpanghoshal/EmoRoBERTa',\n",
    "                           # 'camembert-base'\n",
    "                           # 'cardiffnlp/twitter-roberta-base-irony',\n",
    "                           # 'cardiffnlp/twitter-roberta-base-sentiment-latest',\n",
    "                           # 'ctrl',\n",
    "                           # 'distilroberta-base',\n",
    "                           # 'flaubert/flaubert_base_cased',\n",
    "                           # 'j-hartmann/emotion-english-distilroberta-base',\n",
    "                           # 'joeddav/distilbert-base-uncased-go-emotions-student',\n",
    "                           # 'lxyuan/distilbert-base-multilingual-cased-sentiments-student',\n",
    "                           # 'nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "                           # 'papluca/xlm-roberta-base-language-detection',\n",
    "                           # 'roberta-base',\n",
    "                           # 'xlnet-base-cased',\n",
    "                           # 'facebook/tart-full-flan-t5-xl',\n",
    "                           # 'lytang/MiniCheck-Flan-T5-Large',\n",
    "                          # Need peft on 10GB GPU\n",
    "                            'microsoft/Phi-3-mini-4k-instruct'\n",
    "                           # 'microsoft/phi-2',\n",
    "                           #'meta-llama/Meta-Llama-3-8B',\n",
    "                           #'lightblue/suzume-llama-3-8B-multilingual',\n",
    "                           # 'google/gemma-2b',\n",
    "                           # 'mistralai/Mistral-7B-v0.1',\n",
    "                           #'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "                           ## 'tiiuae/falcon-11B' ,\n",
    "                           ], # Pre-trained model names from the Hugging Face hub used for fine-tuning\n",
    "                    'custom_loader': Phi3ForSequenceClassification,\n",
    "                 # --------------------------\n",
    "                 'split': (0.8, 0.2), # Divides the dataset into training, testing, (and optionally) validation sets. Examples: (0.7,0.3) -> split into train and test proportionally; (70, 30) splits into train,test proportionally.\n",
    "                 'balanced': (('train',), ('test',)),\n",
    "                 # --------------------------\n",
    "                 'training_arguments': {\n",
    "                     'num_train_epochs': 3, # Number of times the model sees the entire training dataset.\n",
    "                     'per_device_train_batch_size': 16, # Number of samples processed in each training step (personally, 8/16 work best, 16 is faster, but you may find linear drop in inference speed during fine-tuning).\n",
    "                     'per_device_eval_batch_size': 16, # Number of samples processed in each evaluation step.\n",
    "                     # 'gradient_accumulation_steps': 4,\n",
    "                     'gradient_checkpointing': True,\n",
    "                     #-----------------------------\n",
    "                     'save_total_limit': 2,\n",
    "                     'load_best_model_at_end': True,\n",
    "                     'save_strategy': 'steps', # Controls when to save model checkpoints ('steps', 'epoch' or 'no').\n",
    "                     'metric_for_best_model': 'f1-score',\n",
    "                     #-----------------------------\n",
    "                     'evaluation_strategy': \"steps\",\n",
    "                     'logging_steps': 100,\n",
    "                     #'max_steps': 20,\n",
    "                     'fp16': False,\n",
    "                     # 'use_cpu': False,\n",
    "                     #-----------------------------\n",
    "                     'learning_rate': 5e-5,\n",
    "                     'lr_scheduler_type': \"linear\",\n",
    "                     'warmup_ratio': 0.1,\n",
    "                     'max_grad_norm': 0.3,\n",
    "                     'weight_decay': 0.001,\n",
    "                 },\n",
    "                 #-----------------------------\n",
    "                     'bnb_config': [\n",
    "                                 #False,\n",
    "                                {'bnb_4bit_compute_dtype': torch.bfloat16, 'load_in_4bit': True, 'bnb_4bit_quant_type': \"nf4\", 'bnb_4bit_use_double_quant': True, 'load_in_8bit': False}\n",
    "                                 ],\n",
    "                 'peft_config': [\n",
    "                                #False,\n",
    "                                {'r': 8, 'lora_alpha': 32, 'lora_dropout': 0.01, 'bias': \"none\",\n",
    "                                'task_type': \"SEQ_CLS\", \n",
    "                                 'target_modules': (\"v_proj\",),\n",
    "                                'target_modules': \"all-linear\"\n",
    "                                }\n",
    "                                ],\n",
    "                    }\n",
    "\n",
    "run_params_serie = prep_config_combinations(run_config)\n",
    "print(len(run_params_serie))\n",
    "run_params_serie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc109c-814b-4b32-9d5e-6951e2b746b4",
   "metadata": {},
   "source": [
    "### Run in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10da002dd892e58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          text\n",
      "label         \n",
      "negative   604\n",
      "neutral   2879\n",
      "positive  1363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b36910abc440f88a2e9e853b168f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce312836a7f449095a766bbf6b17b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b28e8490c42441d9874a47026ae2f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4c853d5b1b40d9ae8c1a6d1c149631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1449 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb5fc0580aa46c0920331a3f4e31454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/363 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b2c6dcfd2841e9a4654c213d57b958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Phi3ForSequenceClassification were not initialized from the model checkpoint at microsoft/Phi-3-mini-4k-instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,616,728 || all params: 3,735,229,488 || trainable%: 0.3378\n",
      "GPU = NVIDIA GeForce RTX 3080. Max memory = 10.0 GB.\n",
      "2.545 GB of memory reserved.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 10:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.123000</td>\n",
       "      <td>0.376117</td>\n",
       "      <td>0.836935</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.833859</td>\n",
       "      <td>0.834711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.521789</td>\n",
       "      <td>0.842538</td>\n",
       "      <td>0.840220</td>\n",
       "      <td>0.834828</td>\n",
       "      <td>0.840220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617.1247 seconds used for training.\n",
      "10.29 minutes used for training.\n",
      "Peak reserved memory = 5.334 GB.\n",
      "Peak reserved memory for training = 2.789 GB.\n",
      "Peak reserved memory % of max memory = 53.34 %.\n",
      "Peak reserved memory for training % of max memory = 27.89 %.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for run_params in run_params_serie:\n",
    "    single_run(run_params, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef3dbbd-8cbc-49a2-b0a6-f16e0b7ab5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
