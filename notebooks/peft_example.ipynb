{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e03f32711a005f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96971ed2-e497-43c4-9a22-47ff7d93c727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install proper version of torch, as according to: https://pytorch.org/\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -e ../.\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from looptune import prep_config_combinations, single_run, clean_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269d739-e320-4d04-aae1-466d6e1f3cbb",
   "metadata": {},
   "source": [
    "### Prepare dataset with two columns: 'text' and 'label'\n",
    "\n",
    "Examplary data source: https://www.kaggle.com/datasets/ankurzing/sentiment-analysis-for-financial-news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca218249-1791-49ec-a1be-fe8927c744e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('example_data/SentimentAnalysisforFinancialNews.csv', encoding=\"ISO-8859-1\", header=None)\n",
    "df.columns = ['label', 'text']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e488de-cfd6-42d1-9280-5823b4394805",
   "metadata": {},
   "source": [
    "### Prepare run configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca629d5cfeeb48dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'meta-llama/Meta-Llama-3-8B',\n",
       "  'split': (0.7, 0.3),\n",
       "  'binary': False,\n",
       "  'balanced': (('train',), ('test',)),\n",
       "  'training_arguments': {'num_train_epochs': 1,\n",
       "   'per_device_train_batch_size': 4,\n",
       "   'per_device_eval_batch_size': 4,\n",
       "   'gradient_checkpointing': True,\n",
       "   'save_total_limit': 2,\n",
       "   'load_best_model_at_end': True,\n",
       "   'save_strategy': 'steps',\n",
       "   'metric_for_best_model': 'f1-score',\n",
       "   'evaluation_strategy': 'steps',\n",
       "   'logging_steps': 100,\n",
       "   'max_steps': 100,\n",
       "   'fp16': False,\n",
       "   'learning_rate': 2e-05,\n",
       "   'lr_scheduler_type': 'linear',\n",
       "   'warmup_ratio': 0.1,\n",
       "   'max_grad_norm': 0.3,\n",
       "   'weight_decay': 0.001},\n",
       "  'bnb_config': {'bnb_4bit_compute_dtype': torch.bfloat16,\n",
       "   'load_in_4bit': True,\n",
       "   'bnb_4bit_quant_type': 'nf4',\n",
       "   'bnb_4bit_use_double_quant': True,\n",
       "   'load_in_8bit': False},\n",
       "  'peft_config': {'r': 8,\n",
       "   'lora_alpha': 32,\n",
       "   'lora_dropout': 0.05,\n",
       "   'bias': 'none',\n",
       "   'task_type': 'SEQ_CLS',\n",
       "   'target_modules': 'all-linear'}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_config = {   # -----------------------\n",
    "                 'model_name': 'meta-llama/Meta-Llama-3-8B', # Pre-trained model names from the Hugging Face hub used for fine-tuning\n",
    "                 # --------------------------\n",
    "                 'split': (0.7, 0.3), # Divides the dataset into training, testing, (and optionally) validation sets. Examples: (0.7,0.3) -> split into train and test proportionally; (70, 30) splits into train,test proportionally.\n",
    "                 'binary': False, # Indicates whether the task is binary (two classes) or multi-class classification.,\n",
    "                 'balanced': (('train',), ('test',)),\n",
    "                 # --------------------------\n",
    "                 'training_arguments': {\n",
    "                     'num_train_epochs': 1, # Number of times the model sees the entire training dataset.\n",
    "                     'per_device_train_batch_size': 4, # Number of samples processed in each training step (personally, 8/16 work best, 16 is faster, but you may find linear drop in inference speed during fine-tuning).\n",
    "                     'per_device_eval_batch_size': 4, # Number of samples processed in each evaluation step.\n",
    "                     # 'gradient_accumulation_steps': 4,\n",
    "                     'gradient_checkpointing': True,\n",
    "                     #-----------------------------\n",
    "                     'save_total_limit': 2,\n",
    "                     'load_best_model_at_end': True,\n",
    "                     'save_strategy': 'steps', # Controls when to save model checkpoints ('steps', 'epoch' or 'no').\n",
    "                     'metric_for_best_model': 'f1-score',\n",
    "                     #-----------------------------\n",
    "                     'evaluation_strategy': \"steps\",\n",
    "                     'logging_steps': 100,\n",
    "                     'max_steps': 100,\n",
    "                     'fp16': False,\n",
    "                     # 'use_cpu': False,\n",
    "                     #-----------------------------\n",
    "                     'learning_rate': 2e-5,\n",
    "                     'lr_scheduler_type': \"linear\",\n",
    "                     'warmup_ratio': 0.1,\n",
    "                     'max_grad_norm': 0.3,\n",
    "                     'weight_decay': 0.001,\n",
    "                 },\n",
    "                 #-----------------------------\n",
    "                     'bnb_config': [\n",
    "                                # False,\n",
    "                                {'bnb_4bit_compute_dtype': torch.bfloat16, 'load_in_4bit': True, 'bnb_4bit_quant_type': \"nf4\", 'bnb_4bit_use_double_quant': True, 'load_in_8bit': False}\n",
    "                                 ],\n",
    "                 'peft_config': [\n",
    "                                # False,\n",
    "                                {'r': 8, 'lora_alpha': 32, 'lora_dropout': 0.05, 'bias': \"none\",\n",
    "                                'task_type': \"SEQ_CLS\", \n",
    "                                # 'target_modules': (\"v_proj\",),\n",
    "                                'target_modules': \"all-linear\"\n",
    "                                }\n",
    "                                ],\n",
    "                    }\n",
    "\n",
    "run_params_serie = prep_config_combinations(run_config)\n",
    "run_params_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc109c-814b-4b32-9d5e-6951e2b746b4",
   "metadata": {},
   "source": [
    "### Run in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10da002dd892e58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          text\n",
      "label         \n",
      "negative   604\n",
      "neutral   2879\n",
      "positive  1363\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb00bea7ea2d4404a1fb004420a938d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/4846 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af5fcad199142af8ad4562fbfcbd74f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56614d4b79ba4fd48d361ef6cb40003d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ced0fc9bbaa43f385a4ec4b005caf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f546e5927f674a3b8adb37a9d6995830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/543 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23554689e5274d9fb09d302570b79432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 21,016,600 || all params: 7,525,986,352 || trainable%: 0.2793\n",
      "none\n",
      "GPU = NVIDIA GeForce RTX 3080. Max memory = 10.0 GB.\n",
      "6.455 GB of memory reserved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 02:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.161800</td>\n",
       "      <td>1.501180</td>\n",
       "      <td>0.436080</td>\n",
       "      <td>0.427256</td>\n",
       "      <td>0.429077</td>\n",
       "      <td>0.427256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.6099 seconds used for training.\n",
      "2.58 minutes used for training.\n",
      "Peak reserved memory = 6.635 GB.\n",
      "Peak reserved memory for training = 0.18 GB.\n",
      "Peak reserved memory % of max memory = 66.35 %.\n",
      "Peak reserved memory for training % of max memory = 1.8 %.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for run_params in run_params_serie:\n",
    "    single_run(run_params, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef3dbbd-8cbc-49a2-b0a6-f16e0b7ab5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
